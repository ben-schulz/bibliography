# text cleaning

[Craig Trim. "The Art of Tokenization"](https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en)
